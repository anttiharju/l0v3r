services:
  web1:
    image: nginx:1.28.0-alpine3.21-slim
    container_name: web1
    environment:
      - SERVER_NAME=Server 1
    command: |
      /bin/sh -c "echo '<html><body><h1>Web Server 1</h1><p>This response is from server 1</p><p>Hostname: '$$(hostname)'</p></body></html>' > /usr/share/nginx/html/index.html && nginx -g 'daemon off;'"
    networks:
      - loadbalancer_network

  web2:
    image: nginx:1.28.0-alpine3.21-slim
    container_name: web2
    environment:
      - SERVER_NAME=Server 2
    command: |
      /bin/sh -c "echo '<html><body><h1>Web Server 2</h1><p>This response is from server 2</p><p>Hostname: '$$(hostname)'</p></body></html>' > /usr/share/nginx/html/index.html && nginx -g 'daemon off;'"
    networks:
      - loadbalancer_network

  web3:
    image: nginx:1.28.0-alpine3.21-slim
    container_name: web3
    environment:
      - SERVER_NAME=Server 3
    command: |
      /bin/sh -c "echo '<html><body><h1>Web Server 3</h1><p>This response is from server 3</p><p>Hostname: '$$(hostname)'</p></body></html>' > /usr/share/nginx/html/index.html && nginx -g 'daemon off;'"
    networks:
      - loadbalancer_network

  haproxy:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: haproxy
    ports:
      - "80:80"
      - "8404:8404"
    volumes:
      - ./test/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
    depends_on:
      - web1
      - web2
      - web3
    # Keep the container running with an interactive terminal
    stdin_open: true
    tty: true
    networks:
      - loadbalancer_network

networks:
  loadbalancer_network:
    driver: bridge
